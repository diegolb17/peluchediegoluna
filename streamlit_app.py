import streamlit as st
import google.generativeai as genai
from gtts import gTTS
import io
import base64

# ================== Configuraci√≥n general ==================
st.set_page_config(page_title="üß∏ Peluche IA", page_icon="üß∏")
st.title("üß∏ Tu Amigo Virtual de Compa√±√≠a")

# üîê Clave API
API_KEY = "AIzaSyAzpQw6qxWMmXx_XMIMv3OABU5ZMvPzfUw"

# Configurar Gemini
try:
    genai.configure(api_key=API_KEY)
    model_chat = genai.GenerativeModel("gemini-2.0-flash")
except Exception as e:
    st.error(f"No se pudo configurar Gemini: {e}")
    st.stop()

# ===== Nombre del ni√±o =====
if "child_name" not in st.session_state:
    st.session_state.child_name = ""

st.session_state.child_name = st.text_input("üë¶üí¨ Escribe tu nombre para que el peluche te llame por √©l:", 
                                            value=st.session_state.child_name)

if not st.session_state.child_name.strip():
    st.info("Por favor escribe tu nombre arriba para comenzar üß∏")
    st.stop()

# ===== Historial =====
if "messages" not in st.session_state:
    # Instrucci√≥n inicial al modelo
    st.session_state.messages = [{
        "role": "system",
        "content": (
            f"Eres un peluche virtual llamado Osito Amigo. "
            f"Tu misi√≥n es acompa√±ar, escuchar y dar apoyo emocional a ni√±os. "
            f"Habla con ternura, sencillez y comprensi√≥n, como un amigo peluche. "
            f"Siempre llama al ni√±o por su nombre: {st.session_state.child_name}. "
            f"Usa frases cortas, sin usar negritas, asteriscos ni s√≠mbolos extra. "
            f"Tu objetivo es que el ni√±o se sienta comprendido y acompa√±ado."
        )
    }]

for m in st.session_state.messages:
    if m["role"] != "system":  # no mostrar instrucciones ocultas
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

# ===== Entrada de texto =====
user_input = st.chat_input(f"Escribe aqu√≠ lo que quieras contarme, {st.session_state.child_name}...")

# ===== Procesar conversaci√≥n =====
if user_input:
    # Mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    # Respuesta del peluche IA
    with st.chat_message("assistant"):
        with st.spinner("‚è≥ Pensando..."):
            try:
                # Pasamos TODO el historial al modelo para coherencia
                prompt = [ {"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages ]
                resp = model_chat.generate_content(prompt)
                answer = (getattr(resp, "text", "") or "").strip() or "No entend√≠ bien, ¬øme cuentas otra vez?"

                # Guardar y mostrar
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.markdown(answer)

                # Convertir a voz autom√°ticamente
                tts = gTTS(answer, lang="es")
                audio_bytes = io.BytesIO()
                tts.write_to_fp(audio_bytes)
                audio_bytes = audio_bytes.getvalue()

                b64 = base64.b64encode(audio_bytes).decode()
                audio_html = f"""
                    <audio autoplay="true">
                        <source src="data:audio/mp3;base64,{b64}" type="audio/mp3">
                    </audio>
                """
                st.markdown(audio_html, unsafe_allow_html=True)

            except Exception as e:
                st.error(f"Error: {e}")
